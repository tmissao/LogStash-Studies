input {
  # Receives Input from a file
  file {
    # Matches everything that beggins `/home/missao/logstash/logstash/event-data/apache_` and ends with `.log`
    path => "/home/missao/logstash/logstash/event-data/apache_*.log"
    start_position => "beginning"
  }
  # Receives a input from an error file
  file {
    path => "/home/missao/logstash/logstash/event-data/java_errors.log"
    start_position => "beginning"
    # Allows to handle multilines events like stacktrace
    codec => multiline {
      # The pattern matches the first line of a multiline event using Grok pattern
      pattern => "^%{CATALINA_DATESTAMP}"
      # Tells codec that every line that does not match the pattern should be grouped in the same event
      negate => true
      what => previous
      auto_flush_interval => 5
    }
  }
}
filter {
  # Checks if the event is an error
  # In the case of http input the request path should contain "error"
  # In the case of file input the file path name should container "error"
  # If true sets the event type to error
  # Else sets the event type to access
  if [headers][request_path] =~ "error" or [path] =~ "error" {
    mutate {
      replace => { type => "error" }
    }
    # Uses Grok to retrieve information in the stacktrace
    grok {
      # extracts: datetime, loglevel, javaclass and the error message using a regex
      match => {
        message => "%{CATALINA_DATESTAMP:timestamp} %{LOGLEVEL:level} %{JAVACLASS:class}: (?<msg>.+?(?=(\r\n|\r|\n)))"
      }
    }
  } else {
    mutate {
      replace => { type => "access" }
    }
    grok {
      # Process HTTPD Message splitting the value
      match => { 
        "message" => '%{HTTPD_COMMONLOG} "%{GREEDYDATA:referrer}" "%{GREEDYDATA:agent}"'
      }
    }

    # Checks if an error ocurred on grok filter
    if "_grokparsefailure" in [tags] {
      # If true drops the event
      drop { }
    }

    # Parses the user agent
    useragent {
      source => "agent"
      target => "user_agent"
      remove_field => ["agent"]
    }

    # Removes Requests to Admin Pages
    if [request] =~ /^\/admin\// {
      drop { }
    }

    # Removes Requests to Static Files
    if [request] =~ /^\/js\// 
      or [request] =~ /^\/css\//
      or [request] in ["/robots.txt", "/favicon.ico"]{
      drop { }
    }

    # Removes Crawlers Requests
    if [user_agent][device] == "Spider" {
      drop { }
    }

    mutate {
      # Converts the string values to integer
      convert => {
        "response" => "integer"
        "bytes" => "integer"
      }
    }
    # Passing dates from fields, and then using that date or timestamp as logstash timestamp
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      # Common options are supported by all filters
      remove_field => ["timestamp"]
    }
    # Enriches data getting location information using the ip address
    geoip {
      source => "clientip"
      fields => ["country_name", "city_name", "location"]
    }

    # Remove unnecessary fields
    mutate {
      remove_field => ["headers", "@version", "host"]
    }
  }
}

output {
  if [type] == "access" {
    elasticsearch {
      hosts => [ "https://<cluster-host>:<cluster-port>" ]
      cloud_auth => "<user>:<password>"
      index => "logstash-%{type}-%{+YYYY-MM-dd}"
      http_compression => true
    }
  }
  else {
    stdout {
      codec => rubydebug
    }
  }
}
